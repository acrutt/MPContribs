{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, json\n",
    "from time import sleep, time\n",
    "from mpcontribs.client import load_client\n",
    "from pymatgen import Structure, MPRester\n",
    "from urllib.request import urlretrieve\n",
    "from monty.json import MontyDecoder\n",
    "from itertools import groupby\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = '2dmatpedia'\n",
    "client = load_client('your-api-key-here')\n",
    "mpr = MPRester()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create project (once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_public = True\n",
    "info = {\n",
    "    'project': project,\n",
    "    'is_public': is_public,\n",
    "    'title': '2DMatPedia',\n",
    "    'long_title': '2D Materials Encyclopedia',\n",
    "    'owner': 'migueldiascosta@nus.edu.sg',\n",
    "    'authors': 'M. Dias Costa, F.Y. Ping, Z. Jun',\n",
    "    'description': ' '.join('''\n",
    "    We start from the around 80000 inorganic compounds in the Materials Project database. A geometry-based\n",
    "    algorithm [PRL] was used to identify layered structures among these compounds. Two-dimensional (2D)\n",
    "    materials were theoretically exfoliated by extracting one cluster in the standard conventional unit cell\n",
    "    of the layered structures screened in the above steps. A 20 Å vacuum along the c axis was imposed to\n",
    "    minimize the interactions of image slabs by periodic condition. Structure matcher tools from Pymatgen were\n",
    "    used to find duplicates of the exfoliated 2D materials. The standard workflow developed by the Materials\n",
    "    Project was used to perform high-throughput calculations for all the layered bulk and 2D materials screened\n",
    "    in this project. The calculations were performed by density functional theory as implemented in the Vienna\n",
    "    Ab Initio Simulation Package (VASP) software with Perdew-Burke-Ernzerhof (PBE) approximation for the\n",
    "    exchange-correlation functional and the frozen-core all-electron projector-augmented wave (PAW) method for\n",
    "    the electron-ion interaction. The cutoff energy for the plane wave expansion was set to 520 eV.\n",
    "    '''.replace('\\n', '').split()),\n",
    "    'urls': {\n",
    "        'WWW': 'http://www.2dmatpedia.org',\n",
    "        'PRL': 'https://doi.org/10.1103/PhysRevLett.118.106101'    \n",
    "    }\n",
    "}\n",
    "# client.projects.create_entry(project=info).result()\n",
    "# client.projects.get_entry(pk=project, _fields=['_all']).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"file\": \"http://www.2dmatpedia.org/static/db.json.gz\",\n",
    "    \"details\": \"http://www.2dmatpedia.org/2dmaterials/doc/{}\",\n",
    "    'columns': {\n",
    "        'material_id': {'name': 'details'},\n",
    "        'exfoliation_energy_per_atom': {'name': 'Eₓ', 'unit': 'eV'},\n",
    "        'energy_per_atom': {'name': 'E', 'unit': 'meV'},\n",
    "        'energy_vdw_per_atom': {'name': 'ΔE|vdW', 'unit': 'meV'},\n",
    "        'bandgap': {'name': 'ΔE', 'unit': 'meV'},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []  # as read from raw files\n",
    "dbfile = config['file'].rsplit('/')[-1]\n",
    "if not os.path.exists(dbfile):\n",
    "    print('downloading', dbfile, '...')\n",
    "    urlretrieve(config['file'], dbfile)\n",
    "\n",
    "with gzip.open(dbfile, 'rb') as f:\n",
    "    for line in f:\n",
    "        raw_data.append(json.loads(line, cls=MontyDecoder))\n",
    "\n",
    "len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data dict from raw data entry\n",
    "def get_data(rd, identifier):\n",
    "    data = {}\n",
    "    for k, col in config['columns'].items():\n",
    "        hdr, unit = col['name'], col.get('unit')\n",
    "        if k == 'material_id':\n",
    "            data[hdr] = config[hdr].format(rd[k])\n",
    "        elif k in rd:\n",
    "            if unit:\n",
    "                try:\n",
    "                    float(rd[k])\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            data[hdr] = f'{rd[k]} {unit}' if unit else rd[k]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_sorted = sorted(raw_data, key=itemgetter('source_id'))\n",
    "raw_data_grouped = {}\n",
    "\n",
    "for task_id, objects in groupby(raw_data_sorted, key=itemgetter('source_id')):\n",
    "    raw_data_grouped[task_id] = list(objects)        \n",
    "\n",
    "print(len(raw_data_sorted), len(raw_data_grouped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions = {}\n",
    "for idx, (task_id, objects) in enumerate(raw_data_grouped.items()):  \n",
    "    if not idx%500:\n",
    "        print(idx, task_id)\n",
    "    \n",
    "    valid = bool(task_id.startswith('mp-') or task_id.startswith('mvc-'))\n",
    "    if valid and task_id not in contributions:\n",
    "        contrib = {'project': project, 'is_public': is_public, 'identifier': task_id, 'data': {}}\n",
    "        structures = []\n",
    "        names = set()\n",
    "        for j, d in enumerate(objects):\n",
    "            structure = d['structure']\n",
    "            comp = d['structure'].composition.reduced_formula\n",
    "            name = f'{comp}|{j}' if comp in names else comp        \n",
    "            names.add(name)\n",
    "            structure = d['structure'].as_dict()\n",
    "            structure.update({'label': '2D', 'name': name, 'is_public': is_public})\n",
    "            structures.append(structure)\n",
    "            label = f'2D|{j}'\n",
    "            contrib['data'][label] = get_data(d, task_id)\n",
    "            contrib['data'][label]['formula'] = comp\n",
    "\n",
    "        contributions[task_id] = {'contrib': contrib, 'structures': structures}\n",
    "\n",
    "print(len(contributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "\n",
    "def chunks(data, SIZE=100):\n",
    "    it = iter(data)\n",
    "    for i in range(0, len(data), SIZE):\n",
    "        if isinstance(data, dict):\n",
    "            yield {k: data[k] for k in islice(it, SIZE)}\n",
    "        else:\n",
    "            yield data[i:i+SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entries():\n",
    "    return [c['id'] for c in client.contributions.get_entries(\n",
    "        project=project, _limit=100, _fields=['id']\n",
    "    ).result()['data']]\n",
    "\n",
    "cids = get_entries()\n",
    "while cids:\n",
    "    cnt = client.contributions.delete_entries(id__in=cids).result()['count']\n",
    "    print(cnt, 'contributions deleted')\n",
    "    cids = get_entries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks(contributions)):\n",
    "    contribs = [c['contrib'] for c in chunk.values()]\n",
    "    created = client.contributions.create_entries(contributions=contribs).result()\n",
    "    print(i, created['count'], 'contributions created')    \n",
    "    \n",
    "    create_structures = []\n",
    "    for contrib in created['data']:\n",
    "        identifier = contrib['identifier']\n",
    "        for s in chunk[identifier]['structures']:\n",
    "            s['contribution'] = contrib['id']\n",
    "            create_structures.append(s)\n",
    "         \n",
    "    print('submit', len(create_structures), 'structures ...')\n",
    "    for j, subchunk in enumerate(chunks(create_structures)):\n",
    "        created = client.structures.create_entries(structures=subchunk).result()\n",
    "        print(j, created['count'], 'structures created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
