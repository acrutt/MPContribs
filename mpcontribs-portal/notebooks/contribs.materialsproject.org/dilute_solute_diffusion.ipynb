{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dated-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpcontribs.client import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "forty-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"dilute_solute_diffusion\"\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, requests, sys\n",
    "from pandas import read_excel, isnull, ExcelWriter, Series\n",
    "from mpcontribs.io.core.recdict import RecursiveDict\n",
    "from mpcontribs.io.core.utils import clean_value, nest_dict\n",
    "from mpcontribs.io.archieml.mpfile import MPFile\n",
    "from pymatgen.ext.matproj import MPRester\n",
    "\n",
    "z = json.load(open(\"z.json\", \"r\"))\n",
    "mpr = MPRester()\n",
    "fpath = f\"{name}.xlsx\"\n",
    "\n",
    "if download or not os.path.exists(fpath):\n",
    "\n",
    "    figshare_id = 1546772\n",
    "    url = \"https://api.figshare.com/v2/articles/{}\".format(figshare_id)\n",
    "    print(\"get figshare article {}\".format(figshare_id))\n",
    "    r = requests.get(url)\n",
    "    figshare = json.loads(r.content)\n",
    "    print(\"version =\", figshare[\"version\"])  # TODO set manually in \"other\"?\n",
    "\n",
    "    print(\"read excel from figshare into DataFrame\")\n",
    "    df_dct = None\n",
    "    for d in figshare[\"files\"]:\n",
    "        if \"xlsx\" in d[\"name\"]:\n",
    "            # Dict of DataFrames is returned, with keys representing sheets\n",
    "            df_dct = read_excel(d[\"download_url\"], sheet_name=None)\n",
    "            break\n",
    "    if df_dct is None:\n",
    "        print(\"no excel sheet found on figshare\")\n",
    "        return\n",
    "\n",
    "    print(\"save excel to disk\")\n",
    "    writer = ExcelWriter(fpath)\n",
    "    for sheet, df in df_dct.items():\n",
    "        df.to_excel(writer, sheet)\n",
    "    writer.save()\n",
    "\n",
    "else:\n",
    "    df_dct = read_excel(fpath, sheet_name=None)\n",
    "\n",
    "print(len(df_dct), \"sheets loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"looping hosts ...\")\n",
    "host_info = df_dct[\"Host Information\"]\n",
    "host_info.set_index(host_info.columns[0], inplace=True)\n",
    "host_info.dropna(inplace=True)\n",
    "\n",
    "for idx, host in enumerate(host_info):\n",
    "    if hosts is not None:\n",
    "        if isinstance(hosts, int) and idx + 1 > hosts:\n",
    "            break\n",
    "        elif isinstance(hosts, list) and not host in hosts:\n",
    "            continue\n",
    "\n",
    "    print(\"get mp-id for {}\".format(host))\n",
    "    mpid = None\n",
    "    for doc in mpr.query(\n",
    "        criteria={\"pretty_formula\": host}, properties={\"task_id\": 1}\n",
    "    ):\n",
    "        if \"decomposes_to\" not in doc[\"sbxd\"][0]:\n",
    "            mpid = doc[\"task_id\"]\n",
    "            break\n",
    "    if mpid is None:\n",
    "        print(\"mp-id for {} not found\".format(host))\n",
    "        continue\n",
    "\n",
    "    print(\"add host info for {}\".format(mpid))\n",
    "    hdata = host_info[host].to_dict(into=RecursiveDict)\n",
    "    for k in list(hdata.keys()):\n",
    "        v = hdata.pop(k)\n",
    "        ks = k.split()\n",
    "        if ks[0] not in hdata:\n",
    "            hdata[ks[0]] = RecursiveDict()\n",
    "        unit = ks[-1][1:-1] if ks[-1].startswith(\"[\") else \"\"\n",
    "        subkey = \"_\".join(ks[1:-1] if unit else ks[1:]).split(\",\")[0]\n",
    "        if subkey == \"lattice_constant\":\n",
    "            unit = \"Å\"\n",
    "        try:\n",
    "            hdata[ks[0]][subkey] = clean_value(v, unit.replace(\"angstrom\", \"Å\"))\n",
    "        except ValueError:\n",
    "            hdata[ks[0]][subkey] = v\n",
    "    hdata[\"formula\"] = host\n",
    "    df = df_dct[\"{}-X\".format(host)]\n",
    "    rows = list(isnull(df).any(1).nonzero()[0])\n",
    "    if rows:\n",
    "        cells = df.iloc[rows].dropna(how=\"all\").dropna(axis=1)[df.columns[0]]\n",
    "        note = cells.iloc[0].replace(\"following\", cells.iloc[1])[:-1]\n",
    "        hdata[\"note\"] = note\n",
    "        df.drop(rows, inplace=True)\n",
    "    mpfile.add_hierarchical_data(nest_dict(hdata, [\"data\"]), identifier=mpid)\n",
    "\n",
    "    print(\"add table for D₀/Q data for {}\".format(mpid))\n",
    "    df.set_index(df[\"Solute element number\"], inplace=True)\n",
    "    df.drop(\"Solute element number\", axis=1, inplace=True)\n",
    "    df.columns = df.iloc[0]\n",
    "    df.index.name = \"index\"\n",
    "    df.drop(\"Solute element name\", inplace=True)\n",
    "    df = df.T.reset_index()\n",
    "    if str(host) == \"Fe\":\n",
    "        df_D0_Q = df[\n",
    "            [\n",
    "                \"Solute element name\",\n",
    "                \"Solute D0, paramagnetic [cm^2/s]\",\n",
    "                \"Solute Q, paramagnetic [eV]\",\n",
    "            ]\n",
    "        ]\n",
    "    elif hdata[\"Host\"][\"crystal_structure\"] == \"HCP\":\n",
    "        df_D0_Q = df[\n",
    "            [\n",
    "                \"Solute element name\",\n",
    "                \"Solute D0 basal [cm^2/s]\",\n",
    "                \"Solute Q basal [eV]\",\n",
    "            ]\n",
    "        ]\n",
    "    else:\n",
    "        df_D0_Q = df[[\"Solute element name\", \"Solute D0 [cm^2/s]\", \"Solute Q [eV]\"]]\n",
    "    df_D0_Q.columns = [\"Solute\", \"D₀ [cm²/s]\", \"Q [eV]\"]\n",
    "    anums = [z[el] for el in df_D0_Q[\"Solute\"]]\n",
    "    df_D0_Q.insert(0, \"Z\", Series(anums, index=df_D0_Q.index))\n",
    "    df_D0_Q.sort_values(\"Z\", inplace=True)\n",
    "    df_D0_Q.reset_index(drop=True, inplace=True)\n",
    "    mpfile.add_data_table(mpid, df_D0_Q, \"D₀_Q\")\n",
    "\n",
    "    if hdata[\"Host\"][\"crystal_structure\"] == \"BCC\":\n",
    "\n",
    "        print(\"add table for hop activation barriers for {} (BCC)\".format(mpid))\n",
    "        columns_E = (\n",
    "            [\"Hop activation barrier, E_{} [eV]\".format(i) for i in range(2, 5)]\n",
    "            + [\"Hop activation barrier, E'_{} [eV]\".format(i) for i in range(3, 5)]\n",
    "            + [\"Hop activation barrier, E''_{} [eV]\".format(i) for i in range(3, 5)]\n",
    "            + [\"Hop activation barrier, E_{} [eV]\".format(i) for i in range(5, 7)]\n",
    "        )\n",
    "        df_E = df[[\"Solute element name\"] + columns_E]\n",
    "        df_E.columns = (\n",
    "            [\"Solute\"]\n",
    "            + [\"E{} [eV]\".format(i) for i in [\"₂\", \"₃\", \"₄\"]]\n",
    "            + [\"E`{} [eV]\".format(i) for i in [\"₃\", \"₄\"]]\n",
    "            + [\"E``{} [eV]\".format(i) for i in [\"₃\", \"₄\"]]\n",
    "            + [\"E{} [eV]\".format(i) for i in [\"₅\", \"₆\"]]\n",
    "        )\n",
    "        mpfile.add_data_table(mpid, df_E, \"hop_activation_barriers\")\n",
    "\n",
    "        print(\"add table for hop attempt frequencies for {} (BCC)\".format(mpid))\n",
    "        columns_v = (\n",
    "            [\"Hop attempt frequency, v_{} [THz]\".format(i) for i in range(2, 5)]\n",
    "            + [\"Hop attempt frequency, v'_{} [THz]\".format(i) for i in range(3, 5)]\n",
    "            + [\"Hop attempt frequency, v''_{} [THz]\".format(i) for i in range(3, 5)]\n",
    "            + [\"Hop attempt frequency, v_{} [THz]\".format(i) for i in range(5, 7)]\n",
    "        )\n",
    "        df_v = df[[\"Solute element name\"] + columns_v]\n",
    "        df_v.columns = (\n",
    "            [\"Solute\"]\n",
    "            + [\"v{} [THz]\".format(i) for i in [\"₂\", \"₃\", \"₄\"]]\n",
    "            + [\"v`{} [THz]\".format(i) for i in [\"₃\", \"₄\"]]\n",
    "            + [\"v``{} [THz]\".format(i) for i in [\"₃\", \"₄\"]]\n",
    "            + [\"v{} [THz]\".format(i) for i in [\"₅\", \"₆\"]]\n",
    "        )\n",
    "        mpfile.add_data_table(mpid, df_v, \"hop_attempt_frequencies\")\n",
    "\n",
    "    elif hdata[\"Host\"][\"crystal_structure\"] == \"FCC\":\n",
    "\n",
    "        print(\"add table for hop activation barriers for {} (FCC)\".format(mpid))\n",
    "        columns_E = [\n",
    "            \"Hop activation barrier, E_{} [eV]\".format(i) for i in range(5)\n",
    "        ]\n",
    "        df_E = df[[\"Solute element name\"] + columns_E]\n",
    "        df_E.columns = [\"Solute\"] + [\n",
    "            \"E{} [eV]\".format(i) for i in [\"₀\", \"₁\", \"₂\", \"₃\", \"₄\"]\n",
    "        ]\n",
    "        mpfile.add_data_table(mpid, df_E, \"hop_activation_barriers\")\n",
    "\n",
    "        print(\"add table for hop attempt frequencies for {} (FCC)\".format(mpid))\n",
    "        columns_v = [\n",
    "            \"Hop attempt frequency, v_{} [THz]\".format(i) for i in range(5)\n",
    "        ]\n",
    "        df_v = df[[\"Solute element name\"] + columns_v]\n",
    "        df_v.columns = [\"Solute\"] + [\n",
    "            \"v{} [THz]\".format(i) for i in [\"₀\", \"₁\", \"₂\", \"₃\", \"₄\"]\n",
    "        ]\n",
    "        mpfile.add_data_table(mpid, df_v, \"hop_attempt_frequencies\")\n",
    "\n",
    "    elif hdata[\"Host\"][\"crystal_structure\"] == \"HCP\":\n",
    "\n",
    "        print(\"add table for hop activation barriers for {} (HCP)\".format(mpid))\n",
    "        columns_E = [\n",
    "            \"Hop activation barrier, E_X [eV]\",\n",
    "            \"Hop activation barrier, E'_X [eV]\",\n",
    "            \"Hop activation barrier, E_a [eV]\",\n",
    "            \"Hop activation barrier, E'_a [eV]\",\n",
    "            \"Hop activation barrier, E_b [eV]\",\n",
    "            \"Hop activation barrier, E'_b [eV]\",\n",
    "            \"Hop activation barrier, E_c [eV]\",\n",
    "            \"Hop activation barrier, E'_c [eV]\",\n",
    "        ]\n",
    "        df_E = df[[\"Solute element name\"] + columns_E]\n",
    "        df_E.columns = [\"Solute\"] + [\n",
    "            \"Eₓ [eV]\",\n",
    "            \"E`ₓ [eV]\",\n",
    "            \"Eₐ [eV]\",\n",
    "            \"E`ₐ [eV]\",\n",
    "            \"E_b [eV]\",\n",
    "            \"E`_b [eV]\",\n",
    "            \"Eꪱ [eV]\",\n",
    "            \"E`ꪱ [eV]\",\n",
    "        ]\n",
    "        mpfile.add_data_table(mpid, df_E, \"hop_activation_barriers\")\n",
    "\n",
    "        print(\"add table for hop attempt frequencies for {} (HCP)\".format(mpid))\n",
    "        columns_v = [\"Hop attempt frequency, v_a [THz]\"] + [\n",
    "            \"Hop attempt frequency, v_X [THz]\"\n",
    "        ]\n",
    "        df_v = df[[\"Solute element name\"] + columns_v]\n",
    "        df_v.columns = [\"Solute\"] + [\"vₐ [THz]\"] + [\"vₓ [THz]\"]\n",
    "        mpfile.add_data_table(mpid, df_v, \"hop_attempt_frequencies\")\n",
    "\n",
    "print(\"DONE\")\n",
    "\n",
    "\n",
    "mpfile = MPFile()\n",
    "mpfile.max_contribs = 15\n",
    "run(mpfile)\n",
    "print(mpfile)\n",
    "\n",
    "filename = f\"{project}.txt\"\n",
    "mpfile.write_file(filename=filename)\n",
    "mpfile = MPFile.from_file(filename)\n",
    "print(len(mpfile.ids))\n",
    "\n",
    "table_names = [\"D₀_Q\", \"hop_activation_barriers\", \"hop_attempt_frequencies\"]\n",
    "\n",
    "for idx, (identifier, content) in enumerate(mpfile.document.items()):\n",
    "    # doc = {'identifier': identifier, 'project': project, 'content': {}}\n",
    "    # doc['content']['data'] = content['data']\n",
    "    # doc['collaborators'] = [{'name': 'Patrick Huck', 'email': 'phuck@lbl.gov'}]\n",
    "    # r = db.contributions.insert_one(doc)\n",
    "    # cid = r.inserted_id\n",
    "    # print(idx, ':', cid)\n",
    "\n",
    "    # tids = []\n",
    "    # for name in table_names:\n",
    "    #    table = mpfile.document[identifier][name]\n",
    "    #    table.pop('@module')\n",
    "    #    table.pop('@class')\n",
    "    #    table['identifier'] = identifier\n",
    "    #    table['project'] = project\n",
    "    #    table['name'] = name\n",
    "    #    table['cid'] = cid\n",
    "    #    r = db.tables.insert_one(table)\n",
    "    #    tids.append(r.inserted_id)\n",
    "\n",
    "    # print(tids)\n",
    "    # query = {'identifier': identifier, 'project': project}\n",
    "    # r = db.contributions.update_one(query, {'$set': {'content.tables': tids}})\n",
    "\n",
    "    name = table_names[0]\n",
    "    query = {\"identifier\": identifier, \"project\": project, \"name\": name}\n",
    "    print(query)\n",
    "    table = mpfile.document[identifier][name]\n",
    "    r = db.tables.update_one(\n",
    "        query, {\"$set\": {\"columns\": table[\"columns\"], \"data\": table[\"data\"]}}\n",
    "    )\n",
    "    print(r.matched_count, r.modified_count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
