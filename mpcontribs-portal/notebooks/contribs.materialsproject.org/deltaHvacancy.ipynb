{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env MPRESTER_MUTE_PROGRESS_BARS 1\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pandas import read_csv\n",
    "from mpcontribs.client import Client\n",
    "from mp_api.client import MPRester\n",
    "from flatten_dict import unflatten\n",
    "from pymatgen.core import Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init clients\n",
    "client = Client(project=\"deltaHvacancy\")\n",
    "mpr = MPRester(api_key=os.environ[\"MPCONTRIBS_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-logging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow non-unique identifiers (disables duplicate checking)\n",
    "client.projects.updateProjectByName(pk=client.project, project={\"unique_identifiers\": False}).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set \"other\" field in project info to explain data columns\n",
    "# appears on hover in contribution section on materials details pages\n",
    "client.projects.updateProjectByName(\n",
    "    pk=client.project, project={\"other\": {\n",
    "        \"dH\": \"vacancy formation enthalpy in eV\",\n",
    "        \"dH|atom\": \"vacancy formation enthalpy in eV/atom\",\n",
    "        \"m\": \"electron effective mass in mₑ\"\n",
    "        # TODO add more as needed\n",
    "    }}\n",
    ").result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-affairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "drivedir = Path(\"/Users/patrick/GoogleDriveLBNL/My Drive/\")\n",
    "datadir = drivedir / Path(\"MaterialsProject/gitrepos/mpcontribs-data/deltaHvacancy/nrel_matdb\")\n",
    "\n",
    "columns_map = {\n",
    "    \"formula\": {\"name\": \"formula\"},\n",
    "    \"defectname\": {\"name\": \"defect\"}, # string\n",
    "    \"site\": {\"name\": \"site\", \"unit\": \"\"}, # dimensionless\n",
    "    \"charge\": {\"name\": \"charge\", \"unit\": \"\"},\n",
    "    \"dH_eV\": {\"name\": \"dH\", \"unit\": \"eV\"},\n",
    "    \"dH_eV_per_atom\": {\"name\": \"dH|atom\", \"unit\": \"eV/atom\"},\n",
    "    \"bandgap_eV\": {\"name\": \"bandgap\", \"unit\": \"eV\"},\n",
    "    \"electron_effective_mass\": {\"name\": \"m\", \"unit\": \"mₑ\"},\n",
    "    \"level_theory\": {\"name\": \"theory\"}\n",
    "}\n",
    "new_column_names = {k: v[\"name\"] for k, v in columns_map.items()}\n",
    "\n",
    "def apply_unit(cell, unit):\n",
    "    return f\"{cell} {unit}\" if unit and cell else cell\n",
    "\n",
    "def apply_units(column):\n",
    "    unit = columns_map[column.name].get(\"unit\")\n",
    "    return column.apply(apply_unit, args=(unit,))\n",
    "\n",
    "contributions = []\n",
    "\n",
    "# NOTE make sure all `_oxstate` and `_POSCAR_wyck` files are gzipped\n",
    "\n",
    "for path in datadir.glob(\"*.csv\"):\n",
    "    prefix, nrel_matdb_id, _ = path.name.split(\".\")\n",
    "    stem = f\"{path.parent}{os.sep}{prefix}.{nrel_matdb_id}\"\n",
    "    poscar_file = f\"{stem}_POSCAR_wyck.gz\"\n",
    "    structure = Structure.from_file(poscar_file, 'POSCAR')\n",
    "    mpid = mpr.find_structure(structure)\n",
    "    identifier = mpid if mpid else nrel_matdb_id\n",
    "    attachments = [Path(poscar_file), Path(f\"{stem}_oxstate.gz\")]\n",
    "    df = read_csv(path).dropna(axis=1, how=\"all\").apply(apply_units).rename(columns=new_column_names)\n",
    "    \n",
    "    for record in df.to_dict(orient=\"records\"):\n",
    "        data = {k: v for k, v in record.items() if v} # clean record\n",
    "        contributions.append({\n",
    "            \"identifier\": identifier,\n",
    "            \"data\": unflatten(data, splitter=\"dot\"),\n",
    "            \"structures\": [structure], \"attachments\": attachments, # duplicates linked internally\n",
    "        })\n",
    "        contributions[-1][\"data\"][\"nrel|id\"] = nrel_matdb_id\n",
    "\n",
    "contributions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-reservoir",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize columns (including units)\n",
    "columns = {\"nrel|id\": None}\n",
    "\n",
    "for col in columns_map.values():\n",
    "    columns[col[\"name\"]] = col.get(\"unit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-rebound",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.delete_contributions() # easier to delete everything for small projects\n",
    "client.init_columns(columns)\n",
    "client.submit_contributions(contributions, ignore_dupes=True)\n",
    "# this shouldn't be necessary but need to re-init columns likely due to bug in API server\n",
    "client.init_columns(columns) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
