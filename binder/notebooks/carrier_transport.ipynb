{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpcontribs.client import load_client\n",
    "from time import sleep, time\n",
    "import gzip, json, os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'carrier_transport'\n",
    "client = load_client('your-api-key-here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get and update project info (see https://portal.mpcontribs.org/carrier_transport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.projects.get_entry(pk=project, _fields=['_all']).result()\n",
    "# client.projects.update_entry(pk=project, project={'long_title': 'Electronic Transport Properties'}).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create contributions with tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/project/projectdirs/matgen/fricci/transport_data/coarse'\n",
    "variables = [\n",
    "    {'key': 'cond_eff_mass', 'name': 'mₑᶜᵒⁿᵈ', 'unit': 'mₑ'},\n",
    "    {'key': 'seebeck_doping', 'name': 'S', 'unit': 'µV/K'},\n",
    "    {'key': 'cond_doping', 'name': 'σ', 'unit': '1/Ω/m/s'},\n",
    "]\n",
    "eigs_keys = ['ε₁', 'ε₂', 'ε₃', 'ε̄']\n",
    "props = {\n",
    "    'seebeck_doping': ['S', 'µV/K'],\n",
    "    'cond_doping': ['σ', '1/Ω/m/s'],\n",
    "    'kappa_doping': ['κₑ', 'W/K/m/s']\n",
    "}\n",
    "pfkey = '⟨S²σ⟩'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in os.scandir(input_dir) if x.is_file()]\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 200\n",
    "interval = 1500\n",
    "for idx, obj in enumerate(files[start:start+interval]):\n",
    "    if not idx%25:\n",
    "        if idx > 0:\n",
    "            stop_time = time()\n",
    "            duration = stop_time-start_time\n",
    "            print(idx, duration)\n",
    "        start_time = time()\n",
    "\n",
    "    contrib = {'project': project, 'identifier': None, 'data': {}}\n",
    "    with gzip.open(obj.path, 'rb') as input_file:\n",
    "        data = json.loads(input_file.read())\n",
    "        contrib['identifier'] = data['mp_id']\n",
    "        task_type = list(data['gap'].keys())[0]\n",
    "        gap = list(data['gap'].values())[0]\n",
    "        contrib['data']['task'] = list(data['task_id'].values())[0]\n",
    "        contrib['data']['type'] = task_type\n",
    "        contrib['data']['metal'] = 'Yes' if gap < 0.1 else 'No'        \n",
    "        contrib['data']['T'] = '300 K'\n",
    "        contrib['data']['doplvl'] = '1e18 cm⁻³'\n",
    "        contrib['data']['ΔE'] = ' '.join([str(gap), 'eV'])\n",
    "        contrib['data']['V'] = ' '.join([str(data['volume']), 'Å³'])\n",
    "        \n",
    "        S2 = None\n",
    "        for v in variables:\n",
    "            for doping_type in ['p', 'n']:\n",
    "                d = data[task_type][v['key']].get(doping_type, {}).get('300', {}).get('1e+18', {})\n",
    "                \n",
    "                if d:\n",
    "                    eigs = d if isinstance(d, list) else d['eigs']\n",
    "                    key = '|'.join([v['name'], doping_type])\n",
    "                    contrib['data'][key] = dict(\n",
    "                        (eigs_keys[neig], ' '.join([str(eig), v['unit']]))\n",
    "                        for neig, eig in enumerate(eigs)\n",
    "                    )\n",
    "                    contrib['data'][key][eigs_keys[-1]] = ' '.join([str(np.mean(eigs)), v['unit']])\n",
    "                    if v['key'] == 'seebeck_doping':\n",
    "                        S2 = np.dot(d['tensor'], d['tensor'])\n",
    "                    elif v['key'] == 'cond_doping':\n",
    "                        pf = np.mean(np.linalg.eigh(np.dot(S2, d['tensor']))[0]) * 1e-8\n",
    "                        if pfkey not in contrib['data']:\n",
    "                            contrib['data'][pfkey] = {}\n",
    "                        contrib['data'][pfkey][doping_type] = ' '.join([str(pf), 'µW/cm/K²/s'])\n",
    "                        \n",
    "        # build data and max values for seebeck, conductivity and kappa\n",
    "        tables = defaultdict(dict)        \n",
    "        for prop_name, (label, unit) in props.items():\n",
    "            for doping_type in ['p', 'n']:\n",
    "                prop = data[task_type][prop_name][doping_type]\n",
    "                prop_averages, dopings, columns = [], None, ['T [K]']\n",
    "                temps = sorted(map(int, prop.keys()))\n",
    "                for temp in temps:\n",
    "                    row = [temp]\n",
    "                    if dopings is None:\n",
    "                        dopings = sorted(map(float, prop[str(temp)].keys()))\n",
    "                    for doping in dopings:\n",
    "                        doping_str = f'{doping:.0e}'\n",
    "                        if len(columns) <= len(dopings):\n",
    "                            columns.append(f'{doping_str} cm⁻³ [{unit}]')\n",
    "                        eigs = prop[str(temp)][doping_str]['eigs']\n",
    "                        row.append(np.mean(eigs))\n",
    "                    prop_averages.append(row)\n",
    "                \n",
    "                table_name = f'{label}({doping_type})'\n",
    "                np_prop_averages = np.array(prop_averages)\n",
    "                tables[table_name] = DataFrame(np_prop_averages, columns=columns)\n",
    "\n",
    "                arr_prop_avg = np.array(np_prop_averages)[:,1:]\n",
    "                max_v = np.max(arr_prop_avg)\n",
    "                if prop_name[0] == 's' and doping_type == 'n':\n",
    "                    max_v = np.min(arr_prop_avg)\n",
    "                if prop_name[0] == 'k':\n",
    "                    max_v = np.min(arr_prop_avg)\n",
    "                arg_max = np.argwhere(arr_prop_avg==max_v)[0]\n",
    "\n",
    "                elabel = label + 'ᵉ'\n",
    "                edoping_type = 'ⁿ' if doping_type == 'n' else 'ᵖ'\n",
    "                contrib['data'][elabel] = {\n",
    "                    doping_type: ' '.join([str(max_v), unit]),\n",
    "                    f'T{edoping_type}': ' '.join([str(temps[arg_max[0]]), 'K']),\n",
    "                    f'c{edoping_type}': ' '.join([str(dopings[arg_max[1]]), 'cm⁻³']),\n",
    "                } \n",
    "\n",
    "    ntries = 0\n",
    "    while ntries < 3:\n",
    "        try:\n",
    "            print(start+idx, contrib['identifier'])\n",
    "            res = client.contributions.get_entries(\n",
    "                project=project, identifier=contrib['identifier'], _fields=['id']\n",
    "            ).result()\n",
    "            cids = [d['id'] for d in res['data']]\n",
    "\n",
    "            for cid in cids:\n",
    "                client.contributions.delete_entry(pk=cid).result()\n",
    "                #print('contribution', cid, 'deleted')\n",
    "\n",
    "            cid = client.contributions.create_entry(contribution=contrib).result()['id']\n",
    "            #print('contribution', cid, 'created')\n",
    "\n",
    "            for name, table in tables.items():\n",
    "                for col in table.columns:\n",
    "                    table[col] = table[col].astype(str)\n",
    "                entry = table.to_dict(orient='split')\n",
    "                entry.pop('index')\n",
    "                entry['contribution'] = cid\n",
    "                entry['name'] = name\n",
    "                tid = client.tables.create_entry(table=entry).result()['id']\n",
    "                #print('table', tid, 'created')\n",
    "            \n",
    "            break\n",
    "        except Exception as ex:\n",
    "            ntries += 1\n",
    "            print(ex)\n",
    "            sleep(30*ntries)\n",
    "    else:\n",
    "        print('I give up.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specific contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrib = client.contributions.get_entry(pk='5e4de5a2fce4e9a91ba1324f', _fields=['_all']).result()\n",
    "contrib['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = contrib['tables'][0]['id']\n",
    "client.tables.get_entry(pk=tid, _fields=['_all']).result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query by materials identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "identifiers = ['mp-2715', 'mp-988', 'mp-9899']\n",
    "client.contributions.get_entries(\n",
    "    project=project, identifier__in=identifiers,\n",
    "    _fields=['identifier', 'formula', 'data.<S>.p.value']\n",
    ").result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query by values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://portal.mpcontribs.org/<project> and\n",
    "# https://api.mpcontribs.org/#/contributions/get_entries\n",
    "\n",
    "limit = 20 # 200 is the limit of retrievable #contributions per page\n",
    "fields = ['<S>', '<σ>', '<S²σ>'] # which data fields to retrieve\n",
    "mask = [f'data.{field}' for field in fields]\n",
    "mask += ['formula', 'identifier']\n",
    "filters = {\n",
    "    'formula__contains': 'Li3',\n",
    "#     'data__<σ>__p__lt': 2e15,\n",
    "#     'data__<σ>__n__lt': 2e15\n",
    "}\n",
    "\n",
    "contribs = client.contributions.get_entries(\n",
    "    project=project, _fields=mask, _limit=limit, **filters\n",
    ").result() # -> see pagination\n",
    "\n",
    "print('found', contribs['total_count'], 'materials')\n",
    "contribs['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pagination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO outdated\n",
    "# only run this once you've optimized masks and filters to what you actually need (see above)\n",
    "all_contribs = []\n",
    "while 1:\n",
    "    page = int(len(all_contribs) / per_page) + 1\n",
    "    contribs = client.contributions.get_entries(\n",
    "        projects=[project], filters=filters, mask=mask, per_page=per_page, page=page\n",
    "    ).result()\n",
    "    all_contribs.extend(contribs)\n",
    "    if not contribs or len(contribs) < per_page:\n",
    "        break\n",
    "\n",
    "print('found', len(all_contribs), 'materials')\n",
    "all_contribs[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
